{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNj+eqSAxMCM6eLEF418tNj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CBaffelli/CAS-NLP_Machine-translation/blob/main/05_CAS_NLP_final_project_data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHT-vcg9IFb2"
      },
      "outputs": [],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data augmentation**\n",
        "\n",
        "This script is used to do data augmentation: swap words and synonym replacement."
      ],
      "metadata": {
        "id": "D-xFEY9PBWqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports and varia\n",
        "import pandas as pd\n",
        "import random\n",
        "import nltk"
      ],
      "metadata": {
        "id": "cSFZzcxxBeYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7hsgLZV_S-Z",
        "outputId": "1187376f-5ff2-47e8-f987-70bca3b27b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load data\n",
        "#Load the datasets\n",
        "italian = pd.read_csv('italian.csv', dtype=str)\n",
        "french = pd.read_csv('french.csv', dtype=str)\n",
        "spanish = pd.read_csv('spanish.csv', dtype=str)\n",
        "romanian = pd.read_csv('romanian.csv', dtype=str)\n",
        "portuguese = pd.read_csv('portuguese.csv', dtype=str)\n",
        "\n",
        "#Mapping for the dataset\n",
        "languages = {\n",
        "    'Italian': italian,\n",
        "    'French': french,\n",
        "    'Spanish' : spanish,\n",
        "    'Romanian' : romanian,\n",
        "    'Portuguese' : portuguese\n",
        "}\n"
      ],
      "metadata": {
        "id": "Zwf3DOBn_dqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Random swap**"
      ],
      "metadata": {
        "id": "Iqo8fj8K-aJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function to swap words, creating a new word order\n",
        "def random_swap(sentence, num_swaps):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "\n",
        "    if len(words) >= 2:\n",
        "        for _ in range(num_swaps):\n",
        "            idx1, idx2 = random.sample(range(len(words)), 2)\n",
        "            new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n",
        "\n",
        "    return ' '.join(new_words)\n"
      ],
      "metadata": {
        "id": "WsCwj8z3-fc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Apply the swap and create new datasets\n",
        "for language_name, language_df in languages.items():\n",
        "  df_output = pd.DataFrame()\n",
        "  df_output['sourceExpression'] = language_df['sourceExpression'].apply(lambda x: random_swap(x, 2))\n",
        "  df_output['targetExpression'] = language_df['targetExpression'].apply(lambda x: random_swap(x, 2))\n",
        "  df_output.to_csv(f'{language_name}_swap.csv', index=False)\n"
      ],
      "metadata": {
        "id": "1-I3JTWk_MUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Synonym replacement**"
      ],
      "metadata": {
        "id": "YHw6jzuiAPL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function to replace words with synonyms\n",
        "#Download wordnet from NLTK\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def synonym_replacement(sentence, num_replacements):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "\n",
        "    for _ in range(num_replacements):\n",
        "        idx = random.randint(0, len(words) - 1)\n",
        "        word = words[idx]\n",
        "\n",
        "        synsets = wordnet.synsets(word)\n",
        "        if synsets:\n",
        "            synonyms = [syn.lemmas()[0].name() for syn in synsets]\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words[idx] = synonym\n",
        "\n",
        "    return ' '.join(new_words)"
      ],
      "metadata": {
        "id": "ImqRMCAlASm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Apply the synonym replacement (to source only) and create new datasets\n",
        "for language_name, language_df in languages.items():\n",
        "  df_output = pd.DataFrame()\n",
        "  df_output['sourceExpression'] = language_df['sourceExpression'].apply(lambda x: synonym_replacement(x, 2))\n",
        "  df_output['targetExpression'] = language_df['targetExpression']\n",
        "  df_output.to_csv(f'{language_name}_synonym.csv', index=False)"
      ],
      "metadata": {
        "id": "ie1qnXjAAcU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}